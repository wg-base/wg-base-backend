spring:
  datasource:
    url: jdbc:mysql://localhost:3306/wg_base?useUnicode=true&characterEncoding=utf-8&&serverTimezone=Asia/Shanghai&useLegacyDatetimeCode=false
    username: root
    password: root
    driver-class-name: com.mysql.cj.jdbc.Driver
  redis:
    database: 0
    host: localhost
    port: 6379
    password: root
    jedis:
      pool:
        max-active: 500
        max-wait: -1
        max-idle: 100
        min-idle: 20
  kafka:
    bootstrap-servers: 10.4.137.102:9092,10.4.137.102:9093,10.40.137.102:9094
    producer:
      retries: 0   # 写入失败重复次数
      batch-size: 16384  # 每次批量发送消息的数量
      buffer-memory: 33554432  # produce积累数据一次发送
      acks: 1
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
    consumer:
      group-id: kafka2  # 指定一个默认的组名
      auto-offset-reset: earliest # earliest:当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，从头开始消费
      # latest:当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，消费新产生的该分区下的数据
      # none:topic各分区都存在已提交的offset时，从offset后开始消费；只要有一个分区不存在已提交的offset，则抛出异常
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
lock:
  redis:
    address: redis://localhost:6379
    password: root